{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectures 1 & 2: Coding Single Neurons and Layers of Neurons\n",
    "A neuron essentially takes in *n* inputs, and has *n* weights (as well as a bias term), and outputs:\n",
    "\n",
    "${x_1}{w_1} + ... + {x_n}{w_n} + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example neuron with three inputs\n",
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2\n",
    "\n",
    "outputs = (inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These neurons can be chained together into a layer, with each input going to each neuron once, looking something like this: \n",
    "\n",
    "![](neuron_layer_diagram.png)\n",
    "\n",
    "This nature plays very well into the mathematical concept of matrices, which is why the network weights are always represented as a $n * i$ matrix (where $n$ is the number of neurons and $i$ is the number of inputs), while the inputs are represented as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.8, 1.21, 2.385]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementing a layer of neurons\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87]\n",
    "]\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "outputs = [\n",
    "    # neuron 1\n",
    "    inputs[0]*weights[0][0] +\n",
    "    inputs[1]*weights[0][1] +\n",
    "    inputs[2]*weights[0][2] +\n",
    "    inputs[3]*weights[0][3] + biases[0],\n",
    "    # neuron 2\n",
    "    inputs[0]*weights[1][0] +\n",
    "    inputs[1]*weights[1][1] +\n",
    "    inputs[2]*weights[1][2] +\n",
    "    inputs[3]*weights[1][3] + biases[1],\n",
    "    # neuron 3\n",
    "    inputs[0]*weights[2][0] +\n",
    "    inputs[1]*weights[2][1] +\n",
    "    inputs[2]*weights[2][2] +\n",
    "    inputs[3]*weights[2][3] + biases[2],\n",
    "]\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2, 6.6000000000000005, 14.2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewriting the layer using loops to reduce the amount of code\n",
    "inputs = [1.1, 2.2, 3.3]\n",
    "weights = [\n",
    "    [2, 0, 0],\n",
    "    [2, 2, 0],\n",
    "    [2, 2, 2],\n",
    "]\n",
    "biases = [0, 0, 1]\n",
    "outputs = []\n",
    "\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    output = 0\n",
    "    for input, weight in zip(inputs, neuron_weights):\n",
    "        output += input * weight\n",
    "    output += neuron_bias\n",
    "    outputs.append(output)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can reduce the amount of code needed even further by using the NumPy Python library (specifically the `np.dot()` dot product operation)\n",
    "\n",
    "The `np.dot()` command can be used in three instances (related to NNs):\n",
    "- Vector x Vector -> Neuron\n",
    "- Vector x Matrix -> Layer\n",
    "- Matrix x Matrix -> Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n",
      "4.8\n"
     ]
    }
   ],
   "source": [
    "# coding a neuron using NumPy\n",
    "import numpy as np\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "# dot product between two vectors is commutative, so we can write it either way\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(outputs)\n",
    "outputs = np.dot(inputs, weights) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  3.465]\n",
      "[4.8   1.21  3.465]\n"
     ]
    }
   ],
   "source": [
    "# coding a layer using NumPy\n",
    "inputs = np.array([1.0, 2.0, 3.0, 2.5])\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, 0.27, 0.17, 0.87],\n",
    "])\n",
    "biases = np.array([2.0, 3.0, 0.5])\n",
    "\n",
    "outputs = np.dot(weights, inputs) + biases\n",
    "print(outputs)\n",
    "# since this is matrix vector multiplication, we can only switch the order of the elements if we transpose the weight matrix\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "# coding a data batch using NumPy\n",
    "inputs = np.array([\n",
    "    [1, 2, 3, 2.5],\n",
    "    [2, 5, -1, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8],\n",
    "])\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87],\n",
    "])\n",
    "biases = np.array([2.0, 3.0, 0.5])\n",
    "\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step will be to chain these layers together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5031 , -1.04185, -2.03875],\n",
       "       [ 0.2434 , -2.7332 , -5.7633 ],\n",
       "       [-0.99314,  1.41254, -0.35655]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([\n",
    "    [1, 2, 3, 2.5],\n",
    "    [2, 5, -1, 2.0],\n",
    "    [-1.5, 2.7, 3.3, -0.8]\n",
    "])\n",
    "weights = np.array([\n",
    "    [0.2, 0.8, -0.5, 1],\n",
    "    [0.5, -0.91, 0.26, -0.5],\n",
    "    [-0.26, -0.27, 0.17, 0.87],\n",
    "])\n",
    "biases = np.array([2.0, 3.0, 0.5])\n",
    "\n",
    "weights2 = np.array([\n",
    "    [0.1, -0.14, 0.5],\n",
    "    [-0.5, 0.12, -0.33],\n",
    "    [-0.44, 0.73, -0.13],\n",
    "])\n",
    "biases2 = np.array([-1, 2, -0.5])\n",
    "\n",
    "layer1_out = np.dot(inputs, weights.T) + biases\n",
    "layer2_out = np.dot(layer1_out, weights2.T) + biases2\n",
    "layer2_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
